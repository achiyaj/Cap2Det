train_reader{
  input_pattern: "/own_files/yekeren/WSOD/output/coco_train.record-*-of-00100" 
  interleave_cycle_length: 1
  is_training: true
  shuffle_buffer_size: 2000
  map_num_parallel_calls: 5
  prefetch_buffer_size: 800
  batch_size: 32
  image_height: 448
  image_width: 448
  image_channels: 3
  max_caption_length: 20
  preprocess_options {
    random_flip_left_right_prob: 0.5
    random_crop_prob: 1.0
    random_crop_min_scale: 0.7
    random_brightness_prob: 0.8
    random_brightness_max_delta: 0.2
    random_contrast_prob: 0.8
    random_contrast_lower: 0.7
    random_contrast_upper: 1.0
    random_hue_prob: 0.2
    random_hue_max_delta: 0.10
    random_saturation_prob: 0.8
    random_saturation_lower: 0.6
    random_saturation_upper: 1.4
  }
}
eval_reader{
  input_pattern: "/own_files/yekeren/WSOD/output/coco_val.record-*-of-00050" 
  interleave_cycle_length: 1
  is_training: false
  shuffle_buffer_size: 2000
  map_num_parallel_calls: 5
  prefetch_buffer_size: 800
  batch_size: 32
  image_height: 448
  image_width: 448
  image_channels: 3
  max_caption_length: 20
}
model_dir: "logs/448_v19"
model {
  [GAPModel.ext] {
    common_dimensions: 50
    cnn_name: "mobilenet_v1"
    cnn_weight_decay: 0.0
    cnn_feature_map: "Conv2d_13_pointwise"
    cnn_checkpoint: "zoo/mobilenet_v1_1.0_224/mobilenet_v1_1.0_224.ckpt"
    vocabulary_file: "output/coco_vocab.txt"
    vocabulary_weights_file: "output/coco_vocab_50d.npy"
    use_saliency_score: true
    triplet_loss_margin: 0.1
    triplet_loss_use_semihard: true
    image_regularizer_weight: 0.0
    text_regularizer_weight: 0.0
    image_proj_hyperparams {
      op: CONV
      activation: NONE
      regularizer {
        l2_regularizer {
          weight: 1e-8
        }
      }
      initializer {
        truncated_normal_initializer {
          mean: 0.0
          stddev: 0.03
        }
      }
      batch_norm {
        decay: 0.999
        center: true
        scale: true
        epsilon: 0.001
      }
    }
    image_saliency_hyperparams {
      op: FC
      activation: NONE
      regularizer {
        l2_regularizer {
          weight: 1e-6
        }
      }
      initializer {
        truncated_normal_initializer {
          mean: 0.0
          stddev: 0.03
        }
      }
      batch_norm {
        decay: 0.999
        center: true
        scale: true
        epsilon: 0.001
      }
    }
    word_saliency_hyperparams {
      op: FC
      activation: NONE
      regularizer {
        l2_regularizer {
          weight: 1e-6
        }
      }
      initializer {
        truncated_normal_initializer {
          mean: 0.0
          stddev: 0.03
        }
      }
      batch_norm {
        decay: 0.999
        center: true
        scale: true
        epsilon: 0.001
      }
    }
  }
}
train_config {
  max_steps: 100000
  learning_rate: 0.003
  optimizer {
    adam {
    }
  }
  save_summary_steps: 500
  save_checkpoints_steps: 1000
  keep_checkpoint_max: 40
  log_step_count_steps: 10
}
eval_config {
  steps: 2000
  start_delay_secs: 300
  throttle_secs: 60
}

