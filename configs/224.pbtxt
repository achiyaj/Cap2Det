train_reader{
  input_pattern: "/own_files/yekeren/WSOD/output/coco_train.record-*-of-00100" 
  interleave_cycle_length: 2
  is_training: true
  shuffle_buffer_size: 1000
  map_num_parallel_calls: 5
  prefetch_buffer_size: 1000
  batch_size: 32
  image_height: 224
  image_width: 224
  image_channels: 3
  max_caption_length: 20
}
eval_reader{
  input_pattern: "/own_files/yekeren/WSOD/output/coco_val.record-*-of-00050" 
  interleave_cycle_length: 2
  is_training: false
  shuffle_buffer_size: 1000
  map_num_parallel_calls: 5
  prefetch_buffer_size: 1000
  batch_size: 32
  image_height: 224
  image_width: 224
  image_channels: 3
  max_caption_length: 20
}
model_dir: "logs/224"
model {
  [GAPModel.ext] {
    common_dimensions: 50
    cnn_name: "mobilenet_v2"
    cnn_weight_decay: 0.0
    cnn_feature_map: "layer_18/output"
    cnn_checkpoint: "zoo/mobilenet_v2_1.0_224/mobilenet_v2_1.0_224.ckpt"
    vocabulary_file: "output/coco_vocab.txt"
    vocabulary_weights_file: "output/coco_vocab_50d.npy"
    use_saliency_score: true
    triplet_loss_margin: 0.1
    triplet_loss_use_semihard: true
    image_regularizer_weight: 1e-5
    text_regularizer_weight: 1e-8
  }
}
train_config {
  max_steps: 120000
  learning_rate: 0.005
  optimizer {
    adam {
    }
  }
  save_summary_steps: 200
  save_checkpoints_steps: 1000
  keep_checkpoint_max: 5
  log_step_count_steps: 10
}
eval_config {
  steps: 200
  start_delay_secs: 60
  throttle_secs: 10
}

